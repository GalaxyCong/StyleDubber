# StyleDubber



## ğŸ“£ News




## ğŸ—’ TODOs
- [x] Release StyleDubber's training and inference code.
- [x] Release pretrained weights.
- [x] Release the raw data and preprocessed data features of the GRID dataset.
- [ ] Update README.md (How to use). 
- [ ] Release the preprocessed data features of the V2C-Animation dataset (chenqi-Denoise2).


## ğŸ“Š Dataset

- GRID ([BaiduDrive](https://pan.baidu.com/s/1E4cPbDvw_Zfk3_F8qoM7JA) (code: GRID) / GoogleDrive)
- V2C-Animation dataset (chenqi-Denoise2) 
  

## ğŸ’¡ Checkpoints

- GRID: https://pan.baidu.com/s/1Mj3MN4TuAEc7baHYNqwbYQ (y8kb)

- V2C-Animation dataset (chenqi-Denoise2): https://pan.baidu.com/s/1hZBUszTaxCTNuHM82ljYWg (n8p5)

## âš’ï¸ Environment

Our python version is ```3.8.18``` and cuda version ```11.5```. It's possible to have other compatible version. 
Both training and inference are implemented with PyTorch on a
GeForce RTX 4090 GPU. 

```bash
conda create -n style_dubber python=3.8.18
conda activate style_dubber
pip install -r requirements.txt
```

## ğŸ”¥ Train Your Own Model 


## â­• Inference 


## âœï¸ Citing


## ğŸ™ Acknowledgments

